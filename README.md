<div align="center">

# ğŸŒŸ Synoptocene: The Future of Video Intelligence

</div>

![Synoptocene Logo](https://img.shields.io/badge/SYNOPSIS_+_SCENE_=_SYNOPTOCENE-00ff88?style=for-the-badge&logo=video&logoColor=black)

### ğŸš€ Revolutionary Video Summarization Through Multimodal AI Fusion

[![Made with Python](https://img.shields.io/badge/Powered%20by-Python%203.12-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![AI Engine](https://img.shields.io/badge/AI%20Engine-CLIP%20%7C%20Whisper%20%7C%20mPLUG--2%20Owl%20%7C%20GPT-ff6b6b?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com)
[![Computer Vision](https://img.shields.io/badge/Computer%20Vision-OpenCV%20%7C%20Optical%20Flow-00d4ff?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org)
[![Vector Intelligence](https://img.shields.io/badge/Vector%20Intelligence-FAISS%20%7C%20PyTorch-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![Web Framework](https://img.shields.io/badge/Web%20Framework-Flask%20%7C%20Bootstrap-6e6e6e?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com)
[![License](https://img.shields.io/badge/License-MIT%20%7C%20Open%20Source-yellow?style=for-the-badge&logo=opensource&logoColor=black)](LICENSE)

---

### ğŸŒŒ Where Video Meets Intelligence

</div>

## ğŸ¯ What Makes Synoptocene Revolutionary

**Synoptocene** is the first-ever implementation of a 7-stage multimodal AI pipeline that revolutionizes how we understand video content. While others use simple frame sampling, we've created something unprecedented:

- ğŸ§  **Dynamic Intelligence**: Adapts to video content in real-time
- ğŸ­ **Motion-Aware Processing**: Understands the pace and intensity of scenes
- ğŸ”— **Multimodal Fusion**: Seamlessly combines video, audio, and text understanding
- âš¡ **Real-Time Adaptation**: Adjusts processing based on content complexity
- ğŸŒŠ **Flow-Based Analysis**: Uses optical flow to understand motion dynamics

---

## ğŸš€ Unprecedented Features

### ğŸ¬ Core Innovation
- **Dynamic Keyframe Extraction**: First-ever pixel-level adaptive frame selection
- **Motion-Aware Processing**: Revolutionary optical flow-based content understanding
- **Intelligent Redundancy Removal**: FAISS-powered similarity detection for perfect diversity
- **Adaptive Snippet Generation**: Motion-intensity based dynamic window sizing

### ğŸ¤– AI-Powered Intelligence
- **CLIP Semantic Scoring**: Context-aware content relevance ranking
- **Whisper Audio Intelligence**: Word-level temporal audio transcription
- **mPLUG-2 Owl Integration**: Multimodal video-audio-text understanding
- **ChatGPT Final Refinement**: Coherent narrative generation from snippets

### ğŸ”§ Technical Excellence
- **GPU Acceleration**: CUDA support for real-time processing
- **Vector Intelligence**: FAISS-based efficient similarity search
- **Temporal Synchronization**: Perfect video-audio alignment
- **Automated Pipeline**: Kaggle integration with Selenium automation

### ğŸŒ Production Ready
- **Enterprise Security**: Environment-based credential management
- **Modern Web Interface**: Responsive design with Bootstrap4
- **User Management**: Secure authentication and session handling
- **Comprehensive Logging**: Detailed metadata and processing insights

---

## ğŸ§± Cutting-Edge Technology Stack

<div align="center">

### ğŸŒŸ The Most Advanced AI Pipeline Ever Assembled

</div>

| ğŸ¯ **Layer** | ğŸš€ **Revolutionary Technologies** | ğŸ”¬ **Research Impact** |
|--------------|-----------------------------------|------------------------|
| **ğŸ§  AI/ML Core** | **CLIP** â€¢ **Whisper** â€¢ **mPLUG-2 Owl** â€¢ **ChatGPT** | State-of-the-art multimodal understanding |
| **ğŸ‘ï¸ Computer Vision** | **OpenCV** â€¢ **DISOpticalFlow** â€¢ **Dynamic Extraction** | Revolutionary motion-aware processing |
| **ğŸ”¢ Vector Intelligence** | **FAISS** â€¢ **PyTorch** â€¢ **NumPy** | Industry-leading similarity search |
| **ğŸµ Audio Processing** | **FFmpeg** â€¢ **PyDub** â€¢ **Audio Segmentation** | Professional-grade audio analysis |
| **ğŸŒ Web Framework** | **Flask** â€¢ **Bootstrap4** â€¢ **SQLAlchemy** | Enterprise-grade web architecture |
| **ğŸ”’ Security Layer** | **Environment Variables** â€¢ **Password Hashing** | Production-ready security standards |

---

### ğŸ† Why This Stack is Revolutionary

- **ğŸ¯ First-Ever Integration**: No other project combines CLIP + Whisper + mPLUG-2 Owl + ChatGPT
- **ğŸŒŠ Motion Intelligence**: Unique optical flow-based content understanding
- **âš¡ Real-Time Adaptation**: Dynamic processing based on content complexity
- **ğŸ”— Multimodal Fusion**: Seamless video-audio-text correlation

---

## ğŸ› ï¸ The Revolutionary 7-Stage AI Pipeline

<div align="center">

### ğŸŒŸ A Breakthrough in Video Intelligence

</div>

**Synoptocene** implements the world's first 7-stage multimodal AI pipeline that revolutionizes video understanding through intelligent content analysis, motion-aware processing, and seamless AI fusion:

#### **Stage 1: Dynamic Keyframe Extraction** ğŸ”
- **Intelligent Frame Selection**: Uses pixel-level difference analysis with configurable thresholds
- **Adaptive Sampling**: Automatically adjusts frame extraction based on visual content changes
- **Memory-Optimized Processing**: Loads entire video into memory for efficient batch processing
- **Configurable Parameters**: `pixel_thresh=30`, `min_interval=10` for optimal keyframe selection

#### **Stage 2: CLIP-Based Content Scoring** ğŸ¯
- **Semantic Understanding**: Leverages OpenAI's CLIP model for content relevance scoring
- **Prompt-Driven Analysis**: Ranks frames based on user-defined relevance criteria
- **Feature Embedding**: Generates high-dimensional feature vectors for each keyframe
- **GPU Acceleration**: Utilizes CUDA for fast parallel processing when available

#### **Stage 3: FAISS-Based Redundancy Pruning** âœ‚ï¸
- **Diversity Filtering**: Implements cosine similarity-based redundancy removal
- **Configurable Thresholds**: `threshold_dot=0.98` for optimal diversity vs. coverage balance
- **Efficient Vector Search**: Uses FAISS for fast similarity computations
- **Quality Preservation**: Maintains high-scoring frames while eliminating duplicates

#### **Stage 4: Motion-Aware Snippet Generation** ğŸï¸
- **Optical Flow Analysis**: Uses OpenCV's DISOpticalFlow for motion intensity measurement
- **Adaptive Window Sizing**: Dynamically adjusts snippet length based on motion:
  - **Fast Motion** (< 0.3): 7-frame windows for detailed analysis
  - **Medium Motion** (0.3-0.7): 5-frame windows for balanced coverage
  - **Slow Motion** (> 0.7): 3-frame windows for concise summaries
- **Temporal Alignment**: Ensures snippets align with audio segments for multimodal coherence

#### **Stage 5: Multimodal Content Analysis** ğŸµ
- **Audio Transcription**: Uses OpenAI Whisper for high-quality speech recognition
- **Word-Level Timestamps**: Precise temporal alignment of audio with video content
- **Segment Synchronization**: Aligns video snippets with corresponding audio segments
- **Metadata Generation**: Comprehensive logging of all processing parameters and results

#### **Stage 6: mPLUG-2 Owl Summarization** ğŸ¦‰
- **Multimodal Understanding**: Processes both video frames and audio transcripts simultaneously
- **Context-Aware Generation**: Creates summaries that correlate visual and auditory content
- **Advanced Language Model**: Leverages state-of-the-art multimodal LLM capabilities
- **Optimized Generation**: Configurable parameters for length, creativity, and coherence

#### **Stage 7: ChatGPT Final Integration** ğŸ¤–
- **Snippet Aggregation**: Combines individual snippet summaries into cohesive narratives
- **Context Refinement**: Enhances summaries with additional context and coherence
- **Quality Assurance**: Ensures final output meets user requirements and standards
- **Selenium Automation**: Seamless integration with web-based ChatGPT interface

### ğŸ”„ **Pipeline Flow Architecture**

```
Video Input â†’ Dynamic Extraction â†’ CLIP Scoring â†’ FAISS Pruning â†’ Motion Analysis â†’ 
Snippet Generation â†’ mPLUG-2 Owl â†’ ChatGPT â†’ Final Summary
```

### âš™ï¸ **Technical Specifications**

- **Video Processing**: OpenCV with configurable resolution (default: 640x360)
- **AI Models**: CLIP, Whisper, mPLUG-2 Owl, ChatGPT
- **Vector Database**: FAISS for efficient similarity search
- **Audio Processing**: FFmpeg integration with 16kHz mono conversion
- **Memory Management**: Optimized for large video files with GPU acceleration
- **Output Format**: MP4 video snippets + WAV audio + JSON metadata

---


## ğŸ§ª Setup & Run

### 1. **Clone the repository**
```bash
git clone https://github.com/shreerajkalbande/Synoptocene.git
cd Synoptocene
```

### 2. **Create a virtual environment (Recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. **Install dependencies**
```bash
pip install -r requirements.txt
```

### 4. **Set up environment variables**
Create a `.env` file in the root directory:

```bash
# Kaggle credentials
KAGGLE_EMAIL=your_actual_kaggle_email
KAGGLE_PASSWORD=your_actual_kaggle_password

# ChatGPT credentials (if needed)
CHATGPT_EMAIL=your_actual_chatgpt_email
CHATGPT_PASSWORD=your_actual_chatgpt_password

# Flask secret key
FLASK_KEY=your_actual_flask_secret_key
FLASK_SECRET_KEY=your_actual_flask_secret_key

# Database URI (if needed)
DB_URI=sqlite:///posts.db
```

**Quick Setup**: Run the interactive setup script:
```bash
python setup_env.py
```

### 5. **Run the application**
```bash
python main.py
```

The Flask app will run on http://localhost:5000

---

## ğŸ”’ Security Features

- **Environment Variables**: All credentials stored securely in `.env` files
- **Password Hashing**: Secure password storage using PBKDF2 with SHA256
- **User Authentication**: Flask-Login integration with session management
- **Input Validation**: Secure form handling and data validation
- **Git History Clean**: Automated cleanup of sensitive data from version control

---

## ğŸ“ Project Structure

```
Synoptocene/
â”œâ”€â”€ main.py                 # Main Flask application
â”œâ”€â”€ forms.py               # Form definitions and validation
â”œâ”€â”€ static/                # Static assets (CSS, JS, images)
â”œâ”€â”€ templates/             # HTML templates
â”œâ”€â”€ instance/              # Database and instance files
â”œâ”€â”€ tests/                 # Test suite
â”œâ”€â”€ setup_env.py          # Environment setup helper
â”œâ”€â”€ cleanup_git_history.sh # Git history cleanup script
â””â”€â”€ SECURITY_CHECKLIST.md  # Security guidelines
```

---

## ğŸ§ª Testing

Run the test suite to ensure everything works correctly:

```bash
python -m pytest tests/
```

---

## ğŸ”¬ Advanced Algorithms

### **Dynamic Keyframe Extraction**
- Pixel-level difference analysis using OpenCV
- Adaptive thresholding for different video types
- Memory-optimized batch processing

### **CLIP-Based Semantic Scoring**
- Multimodal understanding with OpenAI's CLIP
- High-dimensional feature embeddings
- GPU-accelerated processing

### **FAISS Vector Similarity Search**
- Efficient cosine similarity-based redundancy removal
- Scalable processing for large keyframe sets
- Quality preservation through diversity maintenance

### **Motion-Aware Snippet Generation**
- Optical flow analysis using DISOpticalFlow
- Adaptive window sizing based on motion intensity
- Temporal synchronization of video and audio

### **Multimodal AI Integration**
- Whisper for high-quality audio transcription
- mPLUG-2 Owl for multimodal understanding
- ChatGPT for final summary refinement

---

## ğŸš€ Deployment

The application includes a `Procfile` for easy deployment on platforms like Heroku. Ensure your environment variables are properly configured in your deployment environment.

---

## ğŸ“„ License
This project is licensed under the MIT License.

---

## ğŸ¤ Contributions
Feel free to fork, raise issues, or submit PRs to improve this project!

---

## ğŸ† Why Synoptocene is Revolutionary

<div align="center">

### ğŸŒŸ The Future of Video Intelligence is Here

</div>

**Synoptocene** represents a paradigm shift in video processing:

- ğŸš€ **First-Ever Implementation**: No other project combines these 7 AI technologies
- ğŸ§  **Intelligent Processing**: Understands content, not just samples frames
- ğŸŒŠ **Motion-Aware Analysis**: Revolutionary optical flow integration
- ğŸ”— **Multimodal Fusion**: Seamless video-audio-text correlation
- âš¡ **Real-Time Adaptation**: Dynamic processing based on content complexity
- ğŸ¯ **Research-Grade Quality**: Production-ready with academic rigor

---



## ğŸ“ Author 

<div align="center">

### ğŸ§  Shreeraj Kalbande | IIT Kharagpur CSE

**The mind behind the revolution in video intelligence**

[![Email](https://img.shields.io/badge/Email-shreerajkalbande25%40gmail.com-blue?style=for-the-badge&logo=gmail&logoColor=white)](mailto:shreerajkalbande25@gmail.com)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black?style=for-the-badge&logo=github&logoColor=white)](https://github.com/shreerajkalbande)

</div>


