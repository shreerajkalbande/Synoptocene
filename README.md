<div align="center">

# 🌟 Synoptocene: The Future of Video Intelligence

</div>

![Synoptocene Logo](https://img.shields.io/badge/SYNOPSIS_+_SCENE_=_SYNOPTOCENE-00ff88?style=for-the-badge&logo=video&logoColor=black)

### 🚀 Revolutionary Video Summarization Through Multimodal AI Fusion

[![Made with Python](https://img.shields.io/badge/Powered%20by-Python%203.12-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![AI Engine](https://img.shields.io/badge/AI%20Engine-CLIP%20%7C%20Whisper%20%7C%20mPLUG--2%20Owl%20%7C%20GPT-ff6b6b?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com)
[![Computer Vision](https://img.shields.io/badge/Computer%20Vision-OpenCV%20%7C%20Optical%20Flow-00d4ff?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org)
[![Vector Intelligence](https://img.shields.io/badge/Vector%20Intelligence-FAISS%20%7C%20PyTorch-ee4c2c?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![Web Framework](https://img.shields.io/badge/Web%20Framework-Flask%20%7C%20Bootstrap-6e6e6e?style=for-the-badge&logo=flask&logoColor=white)](https://flask.palletsprojects.com)
[![License](https://img.shields.io/badge/License-MIT%20%7C%20Open%20Source-yellow?style=for-the-badge&logo=opensource&logoColor=black)](LICENSE)

---

### 🌌 Where Video Meets Intelligence

</div>

## 🎯 What Makes Synoptocene Revolutionary

**Synoptocene** is the first-ever implementation of a 7-stage multimodal AI pipeline that revolutionizes how we understand video content. While others use simple frame sampling, we've created something unprecedented:

- 🧠 **Dynamic Intelligence**: Adapts to video content in real-time
- 🎭 **Motion-Aware Processing**: Understands the pace and intensity of scenes
- 🔗 **Multimodal Fusion**: Seamlessly combines video, audio, and text understanding
- ⚡ **Real-Time Adaptation**: Adjusts processing based on content complexity
- 🌊 **Flow-Based Analysis**: Uses optical flow to understand motion dynamics

---

## 🚀 Unprecedented Features

### 🎬 Core Innovation
- **Dynamic Keyframe Extraction**: First-ever pixel-level adaptive frame selection
- **Motion-Aware Processing**: Revolutionary optical flow-based content understanding
- **Intelligent Redundancy Removal**: FAISS-powered similarity detection for perfect diversity
- **Adaptive Snippet Generation**: Motion-intensity based dynamic window sizing

### 🤖 AI-Powered Intelligence
- **CLIP Semantic Scoring**: Context-aware content relevance ranking
- **Whisper Audio Intelligence**: Word-level temporal audio transcription
- **mPLUG-2 Owl Integration**: Multimodal video-audio-text understanding
- **ChatGPT Final Refinement**: Coherent narrative generation from snippets

### 🔧 Technical Excellence
- **GPU Acceleration**: CUDA support for real-time processing
- **Vector Intelligence**: FAISS-based efficient similarity search
- **Temporal Synchronization**: Perfect video-audio alignment
- **Automated Pipeline**: Kaggle integration with Selenium automation

### 🌐 Production Ready
- **Enterprise Security**: Environment-based credential management
- **Modern Web Interface**: Responsive design with Bootstrap4
- **User Management**: Secure authentication and session handling
- **Comprehensive Logging**: Detailed metadata and processing insights

---

## 🧱 Cutting-Edge Technology Stack

<div align="center">

### 🌟 The Most Advanced AI Pipeline Ever Assembled

</div>

| 🎯 **Layer** | 🚀 **Revolutionary Technologies** | 🔬 **Research Impact** |
|--------------|-----------------------------------|------------------------|
| **🧠 AI/ML Core** | **CLIP** • **Whisper** • **mPLUG-2 Owl** • **ChatGPT** | State-of-the-art multimodal understanding |
| **👁️ Computer Vision** | **OpenCV** • **DISOpticalFlow** • **Dynamic Extraction** | Revolutionary motion-aware processing |
| **🔢 Vector Intelligence** | **FAISS** • **PyTorch** • **NumPy** | Industry-leading similarity search |
| **🎵 Audio Processing** | **FFmpeg** • **PyDub** • **Audio Segmentation** | Professional-grade audio analysis |
| **🌐 Web Framework** | **Flask** • **Bootstrap4** • **SQLAlchemy** | Enterprise-grade web architecture |
| **🔒 Security Layer** | **Environment Variables** • **Password Hashing** | Production-ready security standards |

---

### 🏆 Why This Stack is Revolutionary

- **🎯 First-Ever Integration**: No other project combines CLIP + Whisper + mPLUG-2 Owl + ChatGPT
- **🌊 Motion Intelligence**: Unique optical flow-based content understanding
- **⚡ Real-Time Adaptation**: Dynamic processing based on content complexity
- **🔗 Multimodal Fusion**: Seamless video-audio-text correlation

---

## 🛠️ The Revolutionary 7-Stage AI Pipeline

<div align="center">

### 🌟 A Breakthrough in Video Intelligence

</div>

**Synoptocene** implements the world's first 7-stage multimodal AI pipeline that revolutionizes video understanding through intelligent content analysis, motion-aware processing, and seamless AI fusion:

#### **Stage 1: Dynamic Keyframe Extraction** 🔍
- **Intelligent Frame Selection**: Uses pixel-level difference analysis with configurable thresholds
- **Adaptive Sampling**: Automatically adjusts frame extraction based on visual content changes
- **Memory-Optimized Processing**: Loads entire video into memory for efficient batch processing
- **Configurable Parameters**: `pixel_thresh=30`, `min_interval=10` for optimal keyframe selection

#### **Stage 2: CLIP-Based Content Scoring** 🎯
- **Semantic Understanding**: Leverages OpenAI's CLIP model for content relevance scoring
- **Prompt-Driven Analysis**: Ranks frames based on user-defined relevance criteria
- **Feature Embedding**: Generates high-dimensional feature vectors for each keyframe
- **GPU Acceleration**: Utilizes CUDA for fast parallel processing when available

#### **Stage 3: FAISS-Based Redundancy Pruning** ✂️
- **Diversity Filtering**: Implements cosine similarity-based redundancy removal
- **Configurable Thresholds**: `threshold_dot=0.98` for optimal diversity vs. coverage balance
- **Efficient Vector Search**: Uses FAISS for fast similarity computations
- **Quality Preservation**: Maintains high-scoring frames while eliminating duplicates

#### **Stage 4: Motion-Aware Snippet Generation** 🎞️
- **Optical Flow Analysis**: Uses OpenCV's DISOpticalFlow for motion intensity measurement
- **Adaptive Window Sizing**: Dynamically adjusts snippet length based on motion:
  - **Fast Motion** (< 0.3): 7-frame windows for detailed analysis
  - **Medium Motion** (0.3-0.7): 5-frame windows for balanced coverage
  - **Slow Motion** (> 0.7): 3-frame windows for concise summaries
- **Temporal Alignment**: Ensures snippets align with audio segments for multimodal coherence

#### **Stage 5: Multimodal Content Analysis** 🎵
- **Audio Transcription**: Uses OpenAI Whisper for high-quality speech recognition
- **Word-Level Timestamps**: Precise temporal alignment of audio with video content
- **Segment Synchronization**: Aligns video snippets with corresponding audio segments
- **Metadata Generation**: Comprehensive logging of all processing parameters and results

#### **Stage 6: mPLUG-2 Owl Summarization** 🦉
- **Multimodal Understanding**: Processes both video frames and audio transcripts simultaneously
- **Context-Aware Generation**: Creates summaries that correlate visual and auditory content
- **Advanced Language Model**: Leverages state-of-the-art multimodal LLM capabilities
- **Optimized Generation**: Configurable parameters for length, creativity, and coherence

#### **Stage 7: ChatGPT Final Integration** 🤖
- **Snippet Aggregation**: Combines individual snippet summaries into cohesive narratives
- **Context Refinement**: Enhances summaries with additional context and coherence
- **Quality Assurance**: Ensures final output meets user requirements and standards
- **Selenium Automation**: Seamless integration with web-based ChatGPT interface

### 🔄 **Pipeline Flow Architecture**

```
Video Input → Dynamic Extraction → CLIP Scoring → FAISS Pruning → Motion Analysis → 
Snippet Generation → mPLUG-2 Owl → ChatGPT → Final Summary
```

### ⚙️ **Technical Specifications**

- **Video Processing**: OpenCV with configurable resolution (default: 640x360)
- **AI Models**: CLIP, Whisper, mPLUG-2 Owl, ChatGPT
- **Vector Database**: FAISS for efficient similarity search
- **Audio Processing**: FFmpeg integration with 16kHz mono conversion
- **Memory Management**: Optimized for large video files with GPU acceleration
- **Output Format**: MP4 video snippets + WAV audio + JSON metadata

---


## 🧪 Setup & Run

### 1. **Clone the repository**
```bash
git clone https://github.com/shreerajkalbande/Synoptocene.git
cd Synoptocene
```

### 2. **Create a virtual environment (Recommended)**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. **Install dependencies**
```bash
pip install -r requirements.txt
```

### 4. **Set up environment variables**
Create a `.env` file in the root directory:

```bash
# Kaggle credentials
KAGGLE_EMAIL=your_actual_kaggle_email
KAGGLE_PASSWORD=your_actual_kaggle_password

# ChatGPT credentials (if needed)
CHATGPT_EMAIL=your_actual_chatgpt_email
CHATGPT_PASSWORD=your_actual_chatgpt_password

# Flask secret key
FLASK_KEY=your_actual_flask_secret_key
FLASK_SECRET_KEY=your_actual_flask_secret_key

# Database URI (if needed)
DB_URI=sqlite:///posts.db
```

**Quick Setup**: Run the interactive setup script:
```bash
python setup_env.py
```

### 5. **Run the application**
```bash
python main.py
```

The Flask app will run on http://localhost:5000

---

## 🔒 Security Features

- **Environment Variables**: All credentials stored securely in `.env` files
- **Password Hashing**: Secure password storage using PBKDF2 with SHA256
- **User Authentication**: Flask-Login integration with session management
- **Input Validation**: Secure form handling and data validation
- **Git History Clean**: Automated cleanup of sensitive data from version control

---

## 📁 Project Structure

```
Synoptocene/
├── main.py                 # Main Flask application
├── forms.py               # Form definitions and validation
├── static/                # Static assets (CSS, JS, images)
├── templates/             # HTML templates
├── instance/              # Database and instance files
├── tests/                 # Test suite
├── setup_env.py          # Environment setup helper
├── cleanup_git_history.sh # Git history cleanup script
└── SECURITY_CHECKLIST.md  # Security guidelines
```

---

## 🧪 Testing

Run the test suite to ensure everything works correctly:

```bash
python -m pytest tests/
```

---

## 🔬 Advanced Algorithms

### **Dynamic Keyframe Extraction**
- Pixel-level difference analysis using OpenCV
- Adaptive thresholding for different video types
- Memory-optimized batch processing

### **CLIP-Based Semantic Scoring**
- Multimodal understanding with OpenAI's CLIP
- High-dimensional feature embeddings
- GPU-accelerated processing

### **FAISS Vector Similarity Search**
- Efficient cosine similarity-based redundancy removal
- Scalable processing for large keyframe sets
- Quality preservation through diversity maintenance

### **Motion-Aware Snippet Generation**
- Optical flow analysis using DISOpticalFlow
- Adaptive window sizing based on motion intensity
- Temporal synchronization of video and audio

### **Multimodal AI Integration**
- Whisper for high-quality audio transcription
- mPLUG-2 Owl for multimodal understanding
- ChatGPT for final summary refinement

---

## 🚀 Deployment

The application includes a `Procfile` for easy deployment on platforms like Heroku. Ensure your environment variables are properly configured in your deployment environment.

---

## 📄 License
This project is licensed under the MIT License.

---

## 🤝 Contributions
Feel free to fork, raise issues, or submit PRs to improve this project!

---

## 🏆 Why Synoptocene is Revolutionary

<div align="center">

### 🌟 The Future of Video Intelligence is Here

</div>

**Synoptocene** represents a paradigm shift in video processing:

- 🚀 **First-Ever Implementation**: No other project combines these 7 AI technologies
- 🧠 **Intelligent Processing**: Understands content, not just samples frames
- 🌊 **Motion-Aware Analysis**: Revolutionary optical flow integration
- 🔗 **Multimodal Fusion**: Seamless video-audio-text correlation
- ⚡ **Real-Time Adaptation**: Dynamic processing based on content complexity
- 🎯 **Research-Grade Quality**: Production-ready with academic rigor

---



## 📝 Author 

<div align="center">

### 🧠 Shreeraj Kalbande | IIT Kharagpur CSE

**The mind behind the revolution in video intelligence**

[![Email](https://img.shields.io/badge/Email-shreerajkalbande25%40gmail.com-blue?style=for-the-badge&logo=gmail&logoColor=white)](mailto:shreerajkalbande25@gmail.com)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black?style=for-the-badge&logo=github&logoColor=white)](https://github.com/shreerajkalbande)

</div>


