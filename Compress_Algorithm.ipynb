{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11136995,"sourceType":"datasetVersion","datasetId":6946466},{"sourceId":11273639,"sourceType":"datasetVersion","datasetId":6938742}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\ndef clear_previous_snippets_and_outputs():\n    \"\"\"\n    Removes the '/kaggle/working/snippets' folder (and all subfolders)\n    plus any 'final_output.txt' file, ensuring a clean slate.\n    \"\"\"\n    snippets_dir = \"/kaggle/working/snippets\"\n    final_output_file = \"/kaggle/working/final_output.txt\"\n\n    # Remove snippet directories\n    if os.path.exists(snippets_dir):\n        shutil.rmtree(snippets_dir)\n        print(f\"Removed old snippet directories at {snippets_dir}\")\n    else:\n        print(f\"No snippet directories found at {snippets_dir}\")\n\n    # Remove final_output.txt if present\n    if os.path.exists(final_output_file):\n        os.remove(final_output_file)\n        print(f\"Removed old final_output.txt at {final_output_file}\")\n    else:\n        print(f\"No final_output.txt found at {final_output_file}\")\n\n# Call it here or in a separate cell before running your main code\nclear_previous_snippets_and_outputs()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:23:08.963853Z","iopub.execute_input":"2025-04-04T10:23:08.964139Z","iopub.status.idle":"2025-04-04T10:23:08.970709Z","shell.execute_reply.started":"2025-04-04T10:23:08.964117Z","shell.execute_reply":"2025-04-04T10:23:08.969969Z"}},"outputs":[{"name":"stdout","text":"No snippet directories found at /kaggle/working/snippets\nNo final_output.txt found at /kaggle/working/final_output.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport subprocess\n\n# Write the entire video summarization code to a file.\n# Note: We convert the pip install command into a subprocess call inside the script.\ncode_content = r'''import subprocess\n\n# ======================\n# 1. Install Dependencies\n# ======================\nsubprocess.run([\"pip\", \"install\", \"--no-cache-dir\", \"opencv-python-headless\", \"ffmpeg-python\", \"pydub\", \"faiss-cpu\", \"torch\", \"torchvision\", \"transformers\", \"openai-whisper==20231106\", \"tqdm\"], check=True)\n\n# ======================\n# 2. Imports\n# ======================\nimport os\nimport cv2\nimport faiss\nimport json\nimport torch\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom pydub import AudioSegment\nfrom typing import List, Dict\nimport torch.nn.functional as F\n\nfrom transformers import CLIPProcessor, CLIPModel\nimport whisper\n\n# ============================\n# 3. Read Entire Video Into Memory\n# ============================\ndef load_entire_video(video_path: str, resize_dim=(640, 240)):\n    print(\"[load_entire_video] Loading all frames into memory...\")\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    if fps <= 0:\n        fps = 30.0\n    frames_in_mem = []\n    idx = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.resize(frame, resize_dim)\n        frames_in_mem.append((frame, idx))\n        idx += 1\n    cap.release()\n    print(f\"[load_entire_video] Loaded {len(frames_in_mem)} frames total.\")\n    return frames_in_mem, fps\n\n# ============================\n# 4. Dynamic Frame Extraction (In Memory)\n# ============================\ndef dynamic_extraction_in_memory(frames_in_mem: List[tuple], pixel_thresh=30, min_interval=10):\n    print(\"[dynamic_extraction_in_memory] Starting dynamic extraction...\")\n    keyframes = []\n    prev_gray = None\n    count = 0\n    for (frame, real_idx) in frames_in_mem:\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        diff_val = 0.0\n        if prev_gray is not None:\n            diff_img = cv2.absdiff(prev_gray, gray)\n            diff_val = float(np.mean(diff_img))\n        if diff_val > pixel_thresh or (count % min_interval == 0):\n            keyframes.append({\n                \"frame\": frame,\n                \"real_index\": real_idx,\n                \"diff_score\": diff_val\n            })\n            prev_gray = gray\n        elif prev_gray is None:\n            prev_gray = gray\n        count += 1\n    print(f\"[dynamic_extraction_in_memory] Extracted {len(keyframes)} keyframes total.\")\n    return keyframes\n\n# ============================\n# 5. CLIP Scoring\n# ============================\ndef clip_score_keyframes(keyframes: List[dict], prompt_emb: np.ndarray, clip_model, clip_proc, device):\n    from torch.nn.functional import normalize\n    print(\"[clip_score_keyframes] Scoring with CLIP...\")\n    results = []\n    for kf in tqdm(keyframes, desc=\"CLIP scoring\"):\n        inp = clip_proc(images=kf[\"frame\"], return_tensors=\"pt\").to(device)\n        with torch.no_grad():\n            img_feat = clip_model.get_image_features(**inp)\n        img_feat = normalize(img_feat, p=2, dim=1).cpu().numpy()\n        dot = float(np.dot(img_feat, prompt_emb.T).squeeze())\n        kf[\"clip_score\"] = dot\n        kf[\"clip_emb\"] = img_feat[0]\n        results.append(kf)\n    results.sort(key=lambda x: x[\"clip_score\"], reverse=True)\n    print(\"[clip_score_keyframes] Done. Sorted descending by clip_score.\")\n    return results\n\n# ============================\n# 6. Diversity Filter (Skip Approach)\n# ============================\ndef diversity_skip(keyframes: List[dict], threshold_dot=0.98):\n    print(f\"[diversity_skip] threshold_dot={threshold_dot}\")\n    final_list = []\n    for kf in keyframes:\n        emb = kf[\"clip_emb\"]\n        keep = True\n        for chosen in final_list:\n            dot_ = float(np.dot(emb, chosen[\"clip_emb\"]))\n            if dot_ > threshold_dot:\n                keep = False\n                break\n        if keep:\n            final_list.append(kf)\n    print(f\"[diversity_skip] After skip => {len(final_list)} frames remain.\")\n    return final_list\n\n# ============================\n# 7. Audio with Whisper\n# ============================\nclass AudioProcessor:\n    def __init__(self):\n        self.audio = None\n        self.word_timestamps = []\n        self.segments = []\n    def extract_and_transcribe(self, video_path: str):\n        audio_path = \"/kaggle/working/tmp_audio.wav\"\n        os.system(f\"ffmpeg -i \\\"{video_path}\\\" -vn -acodec pcm_s16le -ar 16000 -ac 1 \\\"{audio_path}\\\" -y\")\n        print(\"[AudioProcessor] Transcribing with Whisper 'medium' model...\")\n        model = whisper.load_model(\"medium\")\n        result = model.transcribe(audio_path, word_timestamps=True)\n        self.audio = AudioSegment.from_wav(audio_path)\n        self.word_timestamps = []\n        for seg in result[\"segments\"]:\n            self.word_timestamps.extend(seg.get(\"words\", []))\n        self.segments = []\n        for seg in result[\"segments\"]:\n            self.segments.append({\n                \"start\": seg[\"start\"],\n                \"end\": seg[\"end\"],\n                \"text\": seg[\"text\"]\n            })\n    def get_audio_snippet(self, start_f, end_f, fps):\n        if self.audio is None:\n            return None\n        start_ms = (start_f / fps) * 1000\n        end_ms = (end_f / fps) * 1000\n        if end_ms <= start_ms or start_ms >= len(self.audio):\n            return None\n        if end_ms > len(self.audio):\n            end_ms = len(self.audio)\n        return self.audio[start_ms:end_ms]\n\n# ============================\n# 8. Snippet Generation\n# ============================\ndef generate_snippet(frames_in_mem: List[tuple], start_f: int, end_f: int):\n    snippet_frames = []\n    for (frm, idx) in frames_in_mem:\n        if idx >= start_f and idx <= end_f:\n            snippet_frames.append(frm)\n    return snippet_frames\n\ndef measure_local_motion_snippet(snippet_frames: List[np.ndarray], resize_dim=(640,360)):\n    if len(snippet_frames) < 2:\n        return 0.0\n    dis_flow = cv2.DISOpticalFlow_create(cv2.DISOPTICAL_FLOW_PRESET_FAST)\n    gray_list = []\n    for frm in snippet_frames:\n        g = cv2.resize(frm, resize_dim)\n        g = cv2.cvtColor(g, cv2.COLOR_BGR2GRAY)\n        gray_list.append(g)\n    prev = gray_list[0]\n    mags = []\n    for g2 in gray_list[1:]:\n        flow = dis_flow.calc(prev, g2, None)\n        fx, fy = flow[...,0], flow[...,1]\n        mag = np.sqrt(fx**2 + fy**2)\n        mags.append(float(np.mean(mag)))\n        prev = g2\n    return float(np.mean(mags))\n\n# ============================\n# 9. Full Summarizer\n# ============================\nclass VideoSummarizer:\n    def __init__(self, video_path, prompt, top_k=5, resize_dim=(640,360)):\n        self.video_path = video_path\n        self.prompt = prompt\n        self.top_k = top_k\n        self.resize_dim = resize_dim\n        self.out_dir = \"/kaggle/working/snippets\"\n        os.makedirs(self.out_dir, exist_ok=True)\n        self.frames_in_mem, self.fps = load_entire_video(video_path, resize_dim=resize_dim)\n        self.total_frames = len(self.frames_in_mem)\n        print(\"[VideoSummarizer] Loading CLIP model on device.\")\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(self.device)\n        self.clip_proc = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n        from torch.nn.functional import normalize\n        text_inp = self.clip_proc(text=self.prompt, return_tensors=\"pt\").to(self.device)\n        with torch.no_grad():\n            txt_feat = self.clip_model.get_text_features(**text_inp)\n        self.prompt_emb = normalize(txt_feat, p=2, dim=1).cpu().numpy()\n        self.audio_proc = AudioProcessor()\n    def run(self):\n        keyframes = dynamic_extraction_in_memory(self.frames_in_mem, pixel_thresh=30, min_interval=10)\n        if not keyframes:\n            print(\"[VideoSummarizer] No frames after dynamic extraction, aborting.\")\n            return []\n        keyframes = clip_score_keyframes(keyframes, self.prompt_emb, self.clip_model, self.clip_proc, self.device)\n        print(\"[VideoSummarizer] Sorted by clip_score. Top 5 =>\", [kf[\"clip_score\"] for kf in keyframes[:5]])\n        final_list = diversity_skip(keyframes, threshold_dot=0.98)\n        print(f\"[VideoSummarizer] After diversity => {len(final_list)} frames\")\n        final_list = final_list[:self.top_k]\n        print(f\"[VideoSummarizer] Taking top_k={self.top_k} => {len(final_list)} frames\")\n        del self.clip_model\n        del self.clip_proc\n        if self.device == \"cuda\":\n            torch.cuda.empty_cache()\n        self.audio_proc.extract_and_transcribe(self.video_path)\n        final_list.sort(key=lambda x: x[\"real_index\"])\n        snippet_idx = 1\n        results = []\n        for kf in final_list:\n            real_idx = kf[\"real_index\"]\n            start_temp = max(0, real_idx-5)\n            end_temp = min(self.total_frames-1, real_idx+5)\n            snippet_temp = generate_snippet(self.frames_in_mem, start_temp, end_temp)\n            local_mot = measure_local_motion_snippet(snippet_temp, resize_dim=self.resize_dim)\n            if local_mot < 0.3:\n                halfw = 7\n            elif local_mot < 0.7:\n                halfw = 5\n            else:\n                halfw = 3\n            startf = max(0, real_idx-halfw)\n            endf = min(self.total_frames-1, real_idx+halfw)\n            if endf <= startf:\n                print(f\"[Snippet {snippet_idx}] Zero-len snippet => skip. real_idx={real_idx}\")\n                continue\n            start_s = startf / self.fps\n            end_s = endf / self.fps\n            overlapping_segments = []\n            for seg in self.audio_proc.segments:\n                seg_start = seg[\"start\"]\n                seg_end = seg[\"end\"]\n                if seg_end >= start_s and seg_start <= end_s:\n                    overlapping_segments.append(seg)\n            if overlapping_segments:\n                final_seg_start = min(s[\"start\"] for s in overlapping_segments)\n                final_seg_end = max(s[\"end\"] for s in overlapping_segments)\n                startf = int(final_seg_start * self.fps)\n                endf = int(final_seg_end * self.fps)\n                startf = max(0, startf)\n                endf = min(self.total_frames-1, endf)\n                if endf <= startf:\n                    print(f\"[Snippet {snippet_idx}] After expansion, zero-len => skip. real_idx={real_idx}\")\n                    continue\n            snippet_frames = generate_snippet(self.frames_in_mem, startf, endf)\n            final_mot = measure_local_motion_snippet(snippet_frames, resize_dim=self.resize_dim)\n            frames_written = len(snippet_frames)\n            snippet_dir = os.path.join(self.out_dir, f\"snippet_{snippet_idx:03d}\")\n            os.makedirs(snippet_dir, exist_ok=True)\n            out_vid_path = os.path.join(snippet_dir, \"video.mp4\")\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n            outv = cv2.VideoWriter(out_vid_path, fourcc, self.fps, (self.resize_dim[0], self.resize_dim[1]))\n            for frm in snippet_frames:\n                resized = cv2.resize(frm, self.resize_dim)\n                outv.write(resized)\n            outv.release()\n            audio_clip = self.audio_proc.get_audio_snippet(startf, endf, self.fps)\n            audio_path = os.path.join(snippet_dir, \"audio.wav\")\n            if audio_clip:\n                audio_clip.export(audio_path, format=\"wav\")\n            snippet_start_s = float(startf / self.fps)\n            snippet_end_s = float(endf / self.fps)\n            local_words = []\n            for w in self.audio_proc.word_timestamps:\n                w_start = w.get(\"start\", 0.0)\n                if snippet_start_s <= w_start < snippet_end_s:\n                    local_words.append(w)\n            local_segments = []\n            for seg in self.audio_proc.segments:\n                if seg[\"end\"] >= snippet_start_s and seg[\"start\"] <= snippet_end_s:\n                    local_segments.append(seg)\n            meta = {\n                \"real_index\": real_idx,\n                \"diff_score\": kf[\"diff_score\"],\n                \"clip_score\": kf[\"clip_score\"],\n                \"local_motion\": final_mot,\n                \"snippet_start_frame\": startf,\n                \"snippet_end_frame\": endf,\n                \"snippet_start_s\": snippet_start_s,\n                \"snippet_end_s\": snippet_end_s,\n                \"frames_written\": frames_written,\n                \"audio_words\": local_words,\n                \"audio_segments\": local_segments\n            }\n            meta_path = os.path.join(snippet_dir, \"metadata.json\")\n            with open(meta_path, \"w\") as f:\n                import json\n                json.dump(meta, f, indent=2)\n            snippet_secs = frames_written / self.fps\n            print(f\"[Snippet {snippet_idx:03d}] real_idx={real_idx}, clip_score={kf['clip_score']:.2f}, local_mot={final_mot:.2f}, frames={frames_written}, dur={snippet_secs:.2f}s\")\n            snippet_idx += 1\n            results.append(snippet_dir)\n        return results\n\nif __name__ == \"__main__\":\n    dataset_folder = \"/kaggle/input/bro123\"\n\n    # 2) A local JSON file to store previously processed video names\n    processed_json = \"/kaggle/working/processed_videos.json\"\n    \n    # Load or create the list of processed videos\n    if os.path.exists(processed_json):\n        with open(processed_json, \"r\") as f:\n            processed_videos = json.load(f)\n    else:\n        processed_videos = []\n    \n    # Gather all .mp4 files in the dataset folder\n    video_files = [f for f in os.listdir(dataset_folder) if f.lower().endswith(\".mp4\")]\n    video_files.sort()  # optional, just for consistency\n    \n    # Filter to find only the new ones\n    new_videos = [vf for vf in video_files if vf not in processed_videos]\n    \n    if not new_videos:\n        print(\"No new .mp4 files to process.\")\n        VIDEO_PATH = None\n        next_videos = None  # Define next_video as None if no new video exists\n    else:\n        # Pick the first new video\n        next_videos = new_videos[0]\n        VIDEO_PATH = os.path.join(dataset_folder, next_videos)\n        print(f\"Found new video to process: {next_videos}\")\n\n# After processing, only mark as processed if a new video was found.\n    if next_videos is not None:\n        processed_videos.append(next_videos)\n        with open(processed_json, \"w\") as f:\n            json.dump(processed_videos, f)\n        print(f\"Updated processed_videos.json with {next_videos}.\")\n    else:\n        print(\"No new video was processed; processed_videos.json remains unchanged.\")\n\n    print(f\"VIDEO_PATH = {VIDEO_PATH}\")\n    # Now you can process 'video_path' in your code below\n    PROMPT = \"Rank according to relevancy\"\n    TOP_K = 10\n    summarizer = VideoSummarizer(video_path=VIDEO_PATH, prompt=PROMPT, top_k=TOP_K, resize_dim=(640,360))\n    snippet_dirs = summarizer.run()\n    print(f\"\\nGenerated {len(snippet_dirs)} snippet(s) in /kaggle/working/snippets:\")\n    for d in snippet_dirs:\n        print(f\"- {d}\")\n    del summarizer\n    import gc\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    print(\"All models freed and memory cleared.\")\n'''\nif not os.path.exists(\"video_summarization.py\"):\n    with open(\"video_summarization.py\", \"w\") as f:\n        f.write(code_content)\n    print(\"Created video_summarization.py file.\")\nelse:\n    print(\"video_summarization.py already exists. Skipping file creation.\")\n\n# Run the new file as a subprocess.\nresult = subprocess.run([\"python\", \"video_summarization.py\"], capture_output=True, text=True)\n\nprint(\"Subprocess STDOUT:\")\nprint(result.stdout)\nprint(\"Subprocess STDERR:\")\nprint(result.stderr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:23:09.117058Z","iopub.execute_input":"2025-04-04T10:23:09.117342Z","iopub.status.idle":"2025-04-04T10:26:16.467546Z","shell.execute_reply.started":"2025-04-04T10:23:09.117319Z","shell.execute_reply":"2025-04-04T10:26:16.466681Z"}},"outputs":[{"name":"stdout","text":"Created video_summarization.py file.\nSubprocess STDOUT:\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nCollecting ffmpeg-python\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting openai-whisper==20231106\n  Downloading openai-whisper-20231106.tar.gz (798 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.6/798.6 kB 18.4 MB/s eta 0:00:00\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nCollecting triton==2.0.0 (from openai-whisper==20231106)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.26.4)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.9.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.31.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.17.0)\nCollecting lit (from triton==2.0.0->openai-whisper==20231106)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->openai-whisper==20231106) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.43.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper==20231106) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->openai-whisper==20231106) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper==20231106) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->openai-whisper==20231106) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->openai-whisper==20231106) (2024.2.0)\nDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.3/63.3 MB 319.8 MB/s eta 0:00:00\nDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 30.7/30.7 MB 329.9 MB/s eta 0:00:00\nDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.4/96.4 kB 291.4 MB/s eta 0:00:00\nBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml): started\n  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801439 sha256=354f1e5740a752b928959667b0d4d7a2ec2eedf30e208954ca92d9c22188c296\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dxsgepcm/wheels/e6/f6/72/ce51aa2af2b82a54decb6e20e211de3e4787f8a44898a81340\nSuccessfully built openai-whisper\nInstalling collected packages: lit, ffmpeg-python, triton, openai-whisper, faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0 ffmpeg-python-0.2.0 lit-18.1.8 openai-whisper-20231106 triton-2.0.0\nFound new video to process: Vid.mp4\nUpdated processed_videos.json with Vid.mp4.\nVIDEO_PATH = /kaggle/input/bro123/Vid.mp4\n[load_entire_video] Loading all frames into memory...\n[load_entire_video] Loaded 612 frames total.\n[VideoSummarizer] Loading CLIP model on device.\n[dynamic_extraction_in_memory] Starting dynamic extraction...\n[dynamic_extraction_in_memory] Extracted 108 keyframes total.\n[clip_score_keyframes] Scoring with CLIP...\n[clip_score_keyframes] Done. Sorted descending by clip_score.\n[VideoSummarizer] Sorted by clip_score. Top 5 => [0.2362023890018463, 0.2342965304851532, 0.233051136136055, 0.2203814685344696, 0.21898652613162994]\n[diversity_skip] threshold_dot=0.98\n[diversity_skip] After skip => 98 frames remain.\n[VideoSummarizer] After diversity => 98 frames\n[VideoSummarizer] Taking top_k=10 => 10 frames\n[AudioProcessor] Transcribing with Whisper 'medium' model...\n[Snippet 001] real_idx=0, clip_score=0.23, local_mot=3.40, frames=42, dur=1.40s\n[Snippet 002] real_idx=48, clip_score=0.22, local_mot=8.09, frames=7, dur=0.23s\n[Snippet 003] real_idx=50, clip_score=0.22, local_mot=8.94, frames=7, dur=0.23s\n[Snippet 004] real_idx=60, clip_score=0.22, local_mot=3.58, frames=68, dur=2.27s\n[Snippet 005] real_idx=70, clip_score=0.21, local_mot=3.58, frames=68, dur=2.27s\n[Snippet 006] real_idx=244, clip_score=0.21, local_mot=8.50, frames=44, dur=1.47s\n[Snippet 007] real_idx=356, clip_score=0.22, local_mot=14.40, frames=7, dur=0.23s\n[Snippet 008] real_idx=358, clip_score=0.24, local_mot=22.56, frames=7, dur=0.23s\n[Snippet 009] real_idx=580, clip_score=0.22, local_mot=14.98, frames=40, dur=1.33s\n[Snippet 010] real_idx=600, clip_score=0.23, local_mot=14.98, frames=40, dur=1.33s\n\nGenerated 10 snippet(s) in /kaggle/working/snippets:\n- /kaggle/working/snippets/snippet_001\n- /kaggle/working/snippets/snippet_002\n- /kaggle/working/snippets/snippet_003\n- /kaggle/working/snippets/snippet_004\n- /kaggle/working/snippets/snippet_005\n- /kaggle/working/snippets/snippet_006\n- /kaggle/working/snippets/snippet_007\n- /kaggle/working/snippets/snippet_008\n- /kaggle/working/snippets/snippet_009\n- /kaggle/working/snippets/snippet_010\nAll models freed and memory cleared.\n\nSubprocess STDERR:\n2025-04-04 10:23:39.356143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-04 10:23:39.678516: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-04 10:23:39.774718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\nCLIP scoring:   0%|          | 0/108 [00:00<?, ?it/s]\nCLIP scoring:   1%|          | 1/108 [00:00<00:46,  2.31it/s]\nCLIP scoring:   6%|▋         | 7/108 [00:00<00:06, 16.62it/s]\nCLIP scoring:  13%|█▎        | 14/108 [00:00<00:03, 30.06it/s]\nCLIP scoring:  20%|██        | 22/108 [00:00<00:02, 42.28it/s]\nCLIP scoring:  27%|██▋       | 29/108 [00:00<00:01, 49.53it/s]\nCLIP scoring:  35%|███▌      | 38/108 [00:00<00:01, 58.90it/s]\nCLIP scoring:  44%|████▎     | 47/108 [00:01<00:00, 66.33it/s]\nCLIP scoring:  52%|█████▏    | 56/108 [00:01<00:00, 71.79it/s]\nCLIP scoring:  60%|██████    | 65/108 [00:01<00:00, 75.15it/s]\nCLIP scoring:  68%|██████▊   | 73/108 [00:01<00:00, 76.42it/s]\nCLIP scoring:  76%|███████▌  | 82/108 [00:01<00:00, 77.88it/s]\nCLIP scoring:  84%|████████▍ | 91/108 [00:01<00:00, 79.76it/s]\nCLIP scoring:  93%|█████████▎| 100/108 [00:01<00:00, 80.37it/s]\nCLIP scoring: 100%|██████████| 108/108 [00:01<00:00, 59.70it/s]\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from '/kaggle/input/bro123/Vid.mp4':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 1\n    compatible_brands: isommp41mp42\n    creation_time   : 2025-03-01T14:56:28.000000Z\n  Duration: 00:00:20.48, start: 0.000000, bitrate: 7182 kb/s\n  Stream #0:0(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 74 kb/s (default)\n    Metadata:\n      creation_time   : 2025-03-01T14:56:28.000000Z\n      handler_name    : Core Media Audio\n      vendor_id       : [0][0][0][0]\n  Stream #0:1(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 2480x1002, 6693 kb/s, 30 fps, 30 tbr, 600 tbn, 1200 tbc (default)\n    Metadata:\n      creation_time   : 2025-03-01T14:56:28.000000Z\n      handler_name    : Core Media Video\n      vendor_id       : [0][0][0][0]\nStream mapping:\n  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to '/kaggle/working/tmp_audio.wav':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 1\n    compatible_brands: isommp41mp42\n    ISFT            : Lavf58.76.100\n  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n    Metadata:\n      creation_time   : 2025-03-01T14:56:28.000000Z\n      handler_name    : Core Media Audio\n      vendor_id       : [0][0][0][0]\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=       1kB time=00:00:00.00 bitrate=N/A speed=   0x    \nsize=     640kB time=00:00:20.47 bitrate= 256.0kbits/s speed= 585x    \nvideo:0kB audio:640kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.011902%\n\n  0%|                                              | 0.00/1.42G [00:00<?, ?iB/s]\n  0%|▏                                    | 7.00M/1.42G [00:00<00:21, 71.6MiB/s]\n  1%|▍                                    | 15.5M/1.42G [00:00<00:18, 81.6MiB/s]\n  2%|▌                                    | 24.6M/1.42G [00:00<00:17, 87.9MiB/s]\n  2%|▉                                    | 34.9M/1.42G [00:00<00:15, 95.6MiB/s]\n  3%|█                                    | 44.1M/1.42G [00:00<00:16, 89.1MiB/s]\n  4%|█▎                                   | 52.6M/1.42G [00:00<00:16, 88.5MiB/s]\n  4%|█▌                                   | 62.2M/1.42G [00:00<00:15, 92.2MiB/s]\n  5%|█▊                                   | 71.8M/1.42G [00:00<00:15, 94.6MiB/s]\n  6%|██                                   | 80.8M/1.42G [00:00<00:17, 82.0MiB/s]\n  6%|██▎                                  | 89.4M/1.42G [00:01<00:17, 84.1MiB/s]\n  7%|██▍                                  | 98.2M/1.42G [00:01<00:16, 86.5MiB/s]\n  8%|██▊                                   | 110M/1.42G [00:01<00:14, 96.1MiB/s]\n  8%|███                                   | 119M/1.42G [00:01<00:14, 94.7MiB/s]\n  9%|███▎                                  | 128M/1.42G [00:01<00:21, 64.9MiB/s]\n 10%|███▋                                  | 140M/1.42G [00:01<00:18, 76.4MiB/s]\n 10%|███▊                                  | 148M/1.42G [00:01<00:17, 79.5MiB/s]\n 11%|████                                  | 157M/1.42G [00:01<00:16, 84.0MiB/s]\n 11%|████▎                                 | 166M/1.42G [00:02<00:15, 86.8MiB/s]\n 12%|████▌                                 | 175M/1.42G [00:02<00:15, 88.3MiB/s]\n 13%|████▊                                 | 186M/1.42G [00:02<00:14, 94.5MiB/s]\n 13%|█████                                 | 195M/1.42G [00:02<00:14, 90.5MiB/s]\n 14%|█████▎                                | 204M/1.42G [00:03<00:36, 36.0MiB/s]\n 14%|█████▍                                | 211M/1.42G [00:03<00:32, 40.3MiB/s]\n 15%|█████▋                                | 219M/1.42G [00:03<00:27, 47.3MiB/s]\n 16%|█████▉                                | 228M/1.42G [00:03<00:22, 56.5MiB/s]\n 16%|██████▏                               | 239M/1.42G [00:03<00:18, 69.2MiB/s]\n 17%|██████▍                               | 249M/1.42G [00:03<00:16, 76.8MiB/s]\n 18%|██████▊                               | 261M/1.42G [00:03<00:13, 89.9MiB/s]\n 19%|███████                               | 271M/1.42G [00:03<00:13, 90.1MiB/s]\n 19%|███████▎                              | 281M/1.42G [00:03<00:13, 94.4MiB/s]\n 20%|███████▌                              | 292M/1.42G [00:03<00:12, 99.2MiB/s]\n 21%|████████                               | 304M/1.42G [00:04<00:11, 106MiB/s]\n 22%|████████▍                              | 314M/1.42G [00:04<00:11, 103MiB/s]\n 22%|████████▋                              | 324M/1.42G [00:04<00:11, 102MiB/s]\n 23%|████████▉                              | 336M/1.42G [00:04<00:10, 108MiB/s]\n 24%|█████████                             | 346M/1.42G [00:04<00:14, 79.2MiB/s]\n 24%|█████████▎                            | 356M/1.42G [00:04<00:13, 83.0MiB/s]\n 25%|█████████▌                            | 365M/1.42G [00:04<00:13, 83.4MiB/s]\n 26%|█████████▋                            | 373M/1.42G [00:04<00:13, 83.1MiB/s]\n 26%|██████████                            | 384M/1.42G [00:05<00:12, 91.7MiB/s]\n 27%|██████████▎                           | 393M/1.42G [00:05<00:14, 79.6MiB/s]\n 28%|██████████▍                           | 402M/1.42G [00:05<00:13, 80.9MiB/s]\n 28%|██████████▋                           | 410M/1.42G [00:05<00:13, 79.1MiB/s]\n 29%|██████████▉                           | 418M/1.42G [00:05<00:14, 76.5MiB/s]\n 29%|███████████                           | 425M/1.42G [00:05<00:14, 74.9MiB/s]\n 30%|███████████▎                          | 434M/1.42G [00:05<00:13, 78.3MiB/s]\n 30%|███████████▌                          | 444M/1.42G [00:05<00:12, 87.1MiB/s]\n 31%|███████████▊                          | 454M/1.42G [00:05<00:11, 91.1MiB/s]\n 32%|████████████                          | 463M/1.42G [00:06<00:11, 91.4MiB/s]\n 32%|████████████▎                         | 472M/1.42G [00:06<00:11, 91.4MiB/s]\n 33%|████████████▌                         | 481M/1.42G [00:06<00:13, 77.1MiB/s]\n 34%|████████████▊                         | 491M/1.42G [00:06<00:11, 86.1MiB/s]\n 34%|█████████████                         | 501M/1.42G [00:06<00:11, 90.0MiB/s]\n 35%|█████████████▎                        | 510M/1.42G [00:06<00:17, 56.5MiB/s]\n 36%|█████████████▌                        | 519M/1.42G [00:06<00:15, 65.0MiB/s]\n 36%|█████████████▊                        | 528M/1.42G [00:07<00:13, 70.1MiB/s]\n 37%|█████████████▉                        | 536M/1.42G [00:07<00:13, 74.2MiB/s]\n 37%|██████████████▏                       | 546M/1.42G [00:07<00:11, 80.5MiB/s]\n 38%|██████████████▍                       | 554M/1.42G [00:07<00:11, 80.2MiB/s]\n 39%|██████████████▋                       | 562M/1.42G [00:07<00:19, 49.2MiB/s]\n 39%|██████████████▊                       | 570M/1.42G [00:07<00:17, 54.0MiB/s]\n 40%|███████████████                       | 578M/1.42G [00:07<00:14, 62.2MiB/s]\n 40%|███████████████▍                      | 590M/1.42G [00:07<00:11, 76.3MiB/s]\n 41%|███████████████▌                      | 599M/1.42G [00:08<00:11, 77.4MiB/s]\n 42%|███████████████▊                      | 607M/1.42G [00:08<00:11, 78.4MiB/s]\n 42%|████████████████                      | 617M/1.42G [00:08<00:10, 84.2MiB/s]\n 43%|████████████████▎                     | 626M/1.42G [00:08<00:09, 88.4MiB/s]\n 44%|████████████████▋                     | 638M/1.42G [00:08<00:08, 97.3MiB/s]\n 44%|████████████████▉                     | 648M/1.42G [00:08<00:08, 99.2MiB/s]\n 45%|█████████████████▏                    | 657M/1.42G [00:08<00:08, 98.9MiB/s]\n 46%|█████████████████▍                    | 667M/1.42G [00:08<00:08, 93.6MiB/s]\n 46%|█████████████████▋                    | 676M/1.42G [00:08<00:08, 94.3MiB/s]\n 47%|█████████████████▊                    | 685M/1.42G [00:09<00:09, 81.4MiB/s]\n 48%|██████████████████                    | 693M/1.42G [00:09<00:09, 82.1MiB/s]\n 48%|██████████████████▎                   | 701M/1.42G [00:09<00:09, 82.2MiB/s]\n 49%|██████████████████▌                   | 710M/1.42G [00:09<00:10, 78.2MiB/s]\n 49%|██████████████████▋                   | 719M/1.42G [00:09<00:09, 82.9MiB/s]\n 50%|██████████████████▉                   | 727M/1.42G [00:09<00:08, 85.2MiB/s]\n 51%|███████████████████▏                  | 738M/1.42G [00:09<00:08, 91.8MiB/s]\n 51%|███████████████████▍                  | 747M/1.42G [00:09<00:08, 87.4MiB/s]\n 52%|███████████████████▋                  | 755M/1.42G [00:09<00:08, 82.4MiB/s]\n 52%|███████████████████▉                  | 763M/1.42G [00:10<00:08, 82.9MiB/s]\n 53%|████████████████████                  | 771M/1.42G [00:10<00:09, 77.0MiB/s]\n 53%|████████████████████▎                 | 778M/1.42G [00:10<00:09, 75.3MiB/s]\n 54%|████████████████████▌                 | 788M/1.42G [00:10<00:08, 83.2MiB/s]\n 55%|████████████████████▊                 | 797M/1.42G [00:10<00:08, 79.2MiB/s]\n 55%|████████████████████▉                 | 804M/1.42G [00:10<00:08, 78.7MiB/s]\n 56%|█████████████████████▏                | 814M/1.42G [00:10<00:08, 84.3MiB/s]\n 56%|█████████████████████▍                | 822M/1.42G [00:10<00:08, 82.7MiB/s]\n 57%|█████████████████████▋                | 830M/1.42G [00:10<00:08, 82.1MiB/s]\n 57%|█████████████████████▊                | 838M/1.42G [00:11<00:12, 51.7MiB/s]\n 58%|██████████████████████                | 844M/1.42G [00:11<00:12, 53.4MiB/s]\n 59%|██████████████████████▎               | 853M/1.42G [00:11<00:09, 63.5MiB/s]\n 59%|██████████████████████▌               | 864M/1.42G [00:11<00:08, 74.9MiB/s]\n 60%|██████████████████████▊               | 875M/1.42G [00:11<00:07, 84.4MiB/s]\n 61%|███████████████████████               | 883M/1.42G [00:11<00:06, 86.5MiB/s]\n 61%|███████████████████████▎              | 893M/1.42G [00:11<00:06, 91.4MiB/s]\n 62%|███████████████████████▌              | 903M/1.42G [00:12<00:07, 73.2MiB/s]\n 62%|███████████████████████▋              | 910M/1.42G [00:12<00:10, 56.6MiB/s]\n 63%|███████████████████████▉              | 918M/1.42G [00:12<00:09, 60.8MiB/s]\n 64%|████████████████████████▏             | 926M/1.42G [00:12<00:08, 67.0MiB/s]\n 64%|████████████████████████▍             | 938M/1.42G [00:12<00:06, 80.4MiB/s]\n 65%|████████████████████████▋             | 946M/1.42G [00:12<00:06, 77.6MiB/s]\n 65%|████████████████████████▉             | 954M/1.42G [00:12<00:07, 71.5MiB/s]\n 66%|█████████████████████████             | 962M/1.42G [00:12<00:07, 67.6MiB/s]\n 67%|█████████████████████████▎            | 970M/1.42G [00:13<00:07, 72.8MiB/s]\n 67%|█████████████████████████▍            | 978M/1.42G [00:13<00:07, 68.8MiB/s]\n 68%|█████████████████████████▋            | 987M/1.42G [00:13<00:06, 75.5MiB/s]\n 68%|█████████████████████████▉            | 994M/1.42G [00:13<00:06, 76.5MiB/s]\n 69%|█████████████████████████▍           | 0.98G/1.42G [00:13<00:06, 70.3MiB/s]\n 69%|█████████████████████████▌           | 0.99G/1.42G [00:13<00:07, 66.8MiB/s]\n 70%|█████████████████████████▊           | 0.99G/1.42G [00:13<00:06, 71.1MiB/s]\n 70%|██████████████████████████           | 1.00G/1.42G [00:13<00:06, 73.6MiB/s]\n 71%|██████████████████████████▎          | 1.01G/1.42G [00:13<00:05, 88.0MiB/s]\n 72%|██████████████████████████▌          | 1.02G/1.42G [00:14<00:04, 92.8MiB/s]\n 72%|██████████████████████████▊          | 1.03G/1.42G [00:14<00:04, 94.4MiB/s]\n 73%|███████████████████████████          | 1.04G/1.42G [00:14<00:04, 89.8MiB/s]\n 74%|███████████████████████████▎         | 1.05G/1.42G [00:14<00:04, 91.0MiB/s]\n 74%|███████████████████████████▌         | 1.06G/1.42G [00:14<00:04, 92.5MiB/s]\n 75%|███████████████████████████▋         | 1.07G/1.42G [00:14<00:04, 89.6MiB/s]\n 76%|███████████████████████████▉         | 1.08G/1.42G [00:14<00:04, 81.0MiB/s]\n 76%|████████████████████████████▏        | 1.08G/1.42G [00:14<00:04, 83.7MiB/s]\n 77%|████████████████████████████▍        | 1.09G/1.42G [00:14<00:03, 91.3MiB/s]\n 78%|█████████████████████████████▌        | 1.11G/1.42G [00:15<00:03, 100MiB/s]\n 78%|█████████████████████████████▊        | 1.12G/1.42G [00:15<00:03, 105MiB/s]\n 79%|██████████████████████████████        | 1.13G/1.42G [00:15<00:03, 105MiB/s]\n 80%|██████████████████████████████▎       | 1.14G/1.42G [00:15<00:02, 105MiB/s]\n 81%|█████████████████████████████▊       | 1.15G/1.42G [00:15<00:02, 99.4MiB/s]\n 81%|██████████████████████████████▉       | 1.16G/1.42G [00:15<00:02, 102MiB/s]\n 82%|███████████████████████████████▏      | 1.17G/1.42G [00:15<00:02, 109MiB/s]\n 83%|██████████████████████████████▋      | 1.18G/1.42G [00:15<00:03, 86.6MiB/s]\n 83%|██████████████████████████████▊      | 1.19G/1.42G [00:15<00:02, 89.2MiB/s]\n 84%|███████████████████████████████      | 1.20G/1.42G [00:16<00:02, 86.3MiB/s]\n 85%|███████████████████████████████▎     | 1.20G/1.42G [00:16<00:02, 79.4MiB/s]\n 85%|███████████████████████████████▌     | 1.21G/1.42G [00:16<00:02, 79.5MiB/s]\n 86%|███████████████████████████████▊     | 1.22G/1.42G [00:16<00:02, 85.6MiB/s]\n 87%|████████████████████████████████     | 1.23G/1.42G [00:16<00:02, 89.6MiB/s]\n 87%|████████████████████████████████▎    | 1.24G/1.42G [00:16<00:02, 93.6MiB/s]\n 88%|████████████████████████████████▍    | 1.25G/1.42G [00:16<00:02, 84.3MiB/s]\n 88%|████████████████████████████████▋    | 1.26G/1.42G [00:16<00:02, 85.4MiB/s]\n 89%|████████████████████████████████▉    | 1.27G/1.42G [00:16<00:01, 84.4MiB/s]\n 90%|█████████████████████████████████▏   | 1.27G/1.42G [00:17<00:01, 83.2MiB/s]\n 90%|█████████████████████████████████▎   | 1.28G/1.42G [00:17<00:01, 85.0MiB/s]\n 91%|█████████████████████████████████▌   | 1.29G/1.42G [00:17<00:01, 86.4MiB/s]\n 91%|█████████████████████████████████▊   | 1.30G/1.42G [00:17<00:01, 68.2MiB/s]\n 92%|█████████████████████████████████▉   | 1.31G/1.42G [00:17<00:01, 69.6MiB/s]\n 92%|██████████████████████████████████▏  | 1.31G/1.42G [00:17<00:01, 67.6MiB/s]\n 93%|██████████████████████████████████▎  | 1.32G/1.42G [00:17<00:01, 73.2MiB/s]\n 93%|██████████████████████████████████▌  | 1.33G/1.42G [00:17<00:01, 70.5MiB/s]\n 94%|██████████████████████████████████▋  | 1.34G/1.42G [00:17<00:01, 75.4MiB/s]\n 94%|██████████████████████████████████▉  | 1.34G/1.42G [00:18<00:01, 77.5MiB/s]\n 95%|███████████████████████████████████▏ | 1.35G/1.42G [00:18<00:00, 86.5MiB/s]\n 96%|███████████████████████████████████▍ | 1.36G/1.42G [00:18<00:00, 89.7MiB/s]\n 96%|███████████████████████████████████▋ | 1.37G/1.42G [00:18<00:00, 88.9MiB/s]\n 97%|███████████████████████████████████▉ | 1.38G/1.42G [00:18<00:00, 93.6MiB/s]\n 98%|████████████████████████████████████▏| 1.39G/1.42G [00:18<00:00, 95.5MiB/s]\n 98%|████████████████████████████████████▍| 1.40G/1.42G [00:18<00:00, 87.8MiB/s]\n 99%|████████████████████████████████████▌| 1.41G/1.42G [00:18<00:00, 88.9MiB/s]\n100%|████████████████████████████████████▊| 1.42G/1.42G [00:18<00:00, 88.9MiB/s]\n100%|█████████████████████████████████████| 1.42G/1.42G [00:18<00:00, 80.5MiB/s]\n/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n/usr/bin/ld: cannot find -lcuda: No such file or directory\ncollect2: error: ld returned 1 exit status\n/usr/local/lib/python3.10/dist-packages/whisper/timing.py:42: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower median kernel implementation...\n  warnings.warn(\n/usr/bin/ld: cannot find -lcuda: No such file or directory\ncollect2: error: ld returned 1 exit status\n/usr/local/lib/python3.10/dist-packages/whisper/timing.py:146: UserWarning: Failed to launch Triton kernels, likely due to missing CUDA toolkit; falling back to a slower DTW implementation...\n  warnings.warn(\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Change to the working directory\n%cd /kaggle/working\n\n# Clone the mPLUG-Owl repository\n!git clone https://github.com/X-PLUG/mPLUG-Owl.git\n\n# Navigate into the cloned repository\n%cd /kaggle/working/mPLUG-Owl/mPLUG-Owl\n!pip install -r requirements.txt\n!pip install flash-attn\nimport os\n\nSRC_DIR = \"/kaggle/input/final-dataset\"\n\n%cd /kaggle/working/mPLUG-Owl/mPLUG-Owl\nimport torch\nfrom mplug_owl_video.modeling_mplug_owl import MplugOwlForConditionalGeneration\nfrom transformers import AutoTokenizer\nfrom mplug_owl_video.processing_mplug_owl import MplugOwlImageProcessor, MplugOwlProcessor\npretrained_ckpt = SRC_DIR\n\n# 1. Load model with device_map=\"auto\"\nmodel = MplugOwlForConditionalGeneration.from_pretrained(\n    pretrained_ckpt,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",  # Let HF Accelerate handle multi-GPU\n)\n\n# 3. Load processors\nimage_processor = MplugOwlImageProcessor.from_pretrained(pretrained_ckpt)\ntokenizer = AutoTokenizer.from_pretrained(pretrained_ckpt)\nprocessor = MplugOwlProcessor(image_processor, tokenizer)\n    \nprint(\"Model loaded successfully with device_map='auto'!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:26:16.468655Z","iopub.execute_input":"2025-04-04T10:26:16.468934Z","iopub.status.idle":"2025-04-04T10:33:27.638865Z","shell.execute_reply.started":"2025-04-04T10:26:16.468905Z","shell.execute_reply":"2025-04-04T10:33:27.637844Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'mPLUG-Owl'...\nremote: Enumerating objects: 1351, done.\u001b[K\nremote: Counting objects: 100% (266/266), done.\u001b[K\nremote: Compressing objects: 100% (112/112), done.\u001b[K\nremote: Total 1351 (delta 206), reused 154 (delta 154), pack-reused 1085 (from 1)\u001b[K\nReceiving objects: 100% (1351/1351), 34.39 MiB | 39.09 MiB/s, done.\nResolving deltas: 100% (497/497), done.\n/kaggle/working/mPLUG-Owl/mPLUG-Owl\nCollecting transformers==4.28.1 (from -r requirements.txt (line 1))\n  Downloading transformers-4.28.1-py3-none-any.whl.metadata (109 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.8.0)\nCollecting icecream (from -r requirements.txt (line 3))\n  Downloading icecream-2.1.4-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.1.0)\nCollecting ruamel.yaml (from -r requirements.txt (line 5))\n  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\nCollecting uvicorn (from -r requirements.txt (line 6))\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting fastapi (from -r requirements.txt (line 7))\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting markdown2 (from -r requirements.txt (line 8))\n  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\nCollecting gradio (from -r requirements.txt (line 9))\n  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\nCollecting sconf (from -r requirements.txt (line 10))\n  Downloading sconf-0.2.5-py3-none-any.whl.metadata (3.9 kB)\nCollecting tensorboardX (from -r requirements.txt (line 11))\n  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.17.1)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.12.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.2.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.14.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (4.10.0.84)\nCollecting decord (from -r requirements.txt (line 17))\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (5.2.0)\nCollecting cchardet (from -r requirements.txt (line 19))\n  Downloading cchardet-2.1.7.tar.gz (653 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (2.32.3)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1->-r requirements.txt (line 1))\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1->-r requirements.txt (line 1)) (4.67.1)\nRequirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream->-r requirements.txt (line 3)) (0.4.6)\nRequirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream->-r requirements.txt (line 3)) (2.19.1)\nCollecting executing>=2.1.0 (from icecream->-r requirements.txt (line 3))\n  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream->-r requirements.txt (line 3)) (3.0.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 4)) (3.1.3)\nRequirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 4)) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 4)) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 4)) (8.1.7)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 4)) (1.9.0)\nCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->-r requirements.txt (line 5))\n  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 6)) (0.14.0)\nRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 6)) (4.12.2)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi->-r requirements.txt (line 7))\n  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 7)) (2.11.0a2)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (3.7.1)\nCollecting ffmpy (from gradio->-r requirements.txt (line 9))\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.8.0 (from gradio->-r requirements.txt (line 9))\n  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio->-r requirements.txt (line 9))\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (0.28.1)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (3.10.12)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (11.0.0)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 9))\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting ruff>=0.9.3 (from gradio->-r requirements.txt (line 9))\n  Downloading ruff-0.11.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 9))\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 9))\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 9))\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 9)) (0.15.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio->-r requirements.txt (line 9)) (2024.12.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio->-r requirements.txt (line 9)) (14.1)\nCollecting munch (from sconf->-r requirements.txt (line 10))\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 11)) (3.20.3)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.7)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (75.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 15)) (5.9.5)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 15)) (2.5.1+cu121)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 15)) (1.2.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft->-r requirements.txt (line 15)) (0.4.5)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 9)) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 9)) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 9)) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 9)) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 9)) (1.0.7)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 9)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 9)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 9)) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r requirements.txt (line 7)) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->-r requirements.txt (line 7)) (2.29.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft->-r requirements.txt (line 15)) (3.4.2)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft->-r requirements.txt (line 15)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft->-r requirements.txt (line 15)) (1.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (13.9.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->-r requirements.txt (line 1)) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1->-r requirements.txt (line 1)) (2.3.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (3.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.28.1->-r requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 9)) (0.1.2)\nDownloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading icecream-2.1.4-py3-none-any.whl (14 kB)\nDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sconf-0.2.5-py3-none-any.whl (8.8 kB)\nDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\nDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ruff-0.11.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: cchardet\n  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=289388 sha256=bf81cc48b62c33c07e85e904306ed814177d1f416fc505f1a8c2c44d8e24e2c0\n  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\nSuccessfully built cchardet\nInstalling collected packages: tokenizers, cchardet, uvicorn, tomlkit, semantic-version, ruff, ruamel.yaml.clib, python-multipart, munch, markdown2, groovy, ffmpy, executing, starlette, ruamel.yaml, icecream, sconf, safehttpx, gradio-client, fastapi, transformers, tensorboardX, gradio, decord\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires transformers>=4.33.1, but you have transformers 4.28.1 which is incompatible.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.28.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cchardet-2.1.7 decord-0.6.0 executing-2.2.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 icecream-2.1.4 markdown2-2.5.3 munch-4.0.0 python-multipart-0.0.20 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 ruff-0.11.3 safehttpx-0.1.6 sconf-0.2.5 semantic-version-2.10.0 starlette-0.46.1 tensorboardX-2.6.2.2 tokenizers-0.13.3 tomlkit-0.13.2 transformers-4.28.1 uvicorn-0.34.0\nCollecting flash-attn\n  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.5.1+cu121)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\nBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\nSuccessfully built flash-attn\nInstalling collected packages: flash-attn\nSuccessfully installed flash-attn-2.7.4.post1\n/kaggle/working/mPLUG-Owl/mPLUG-Owl\ninstall flash-attn first.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=\"cpu\")\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully with device_map='auto'!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport json\nimport glob\n\n###########################\n# 2. Your Generation Settings (adjusted)\n###########################\ngenerate_kwargs = {\n    'do_sample': False,\n    'top_k': 5,\n    'max_length': 70,   # Increased to allow for longer summaries\n    'temperature': 0.5,\n    'top_p': 0.9,\n    'num_beams': 1,\n    'no_repeat_ngram_size': 2,\n    'early_stopping': True,\n    'length_penalty': 1\n}\n\n###########################\n# 3. Define getDescription\n###########################\ndef getDescription(prompts, video_list, generate_kwargs, nframes=48):\n    \"\"\"\n    Summarize a video using your loaded mPLUG-Owl model.\n    \"\"\"\n    # Convert text+videos into model inputs\n    inputs = processor(text=prompts, videos=video_list, num_frames=nframes, return_tensors='pt')\n    # Convert float => bfloat16 if needed\n    inputs = {\n        k: v.bfloat16() if (torch.is_floating_point(v) and v.dtype == torch.float32) else v\n        for k, v in inputs.items()\n    }\n    # Move inputs to GPU\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        res = model.generate(**inputs, **generate_kwargs)\n    sentence = tokenizer.decode(res[0], skip_special_tokens=True)\n    return sentence\n\n###########################\n# 4. Summarize All Snippets\n###########################\ndef summarize_snippets(snippet_base=\"/kaggle/working/snippets\", snippet_count=10):\n    snippet_summaries = []\n\n    for i in range(1, snippet_count + 1):\n        snippet_dir = os.path.join(snippet_base, f\"snippet_{i:03d}\")\n        video_path  = os.path.join(snippet_dir, \"video.mp4\")\n        meta_path   = os.path.join(snippet_dir, \"metadata.json\")\n\n        if not os.path.exists(video_path):\n            print(f\"[WARNING] Missing video.mp4 in {snippet_dir}, skipping.\")\n            snippet_summaries.append(None)\n            continue\n\n        if not os.path.exists(meta_path):\n            print(f\"[WARNING] Missing metadata.json in {snippet_dir}, skipping.\")\n            snippet_summaries.append(None)\n            continue\n\n        # Load metadata\n        with open(meta_path, \"r\") as f:\n            meta = json.load(f)\n\n        # Extract audio text from audio_segments\n        audio_segments = meta.get(\"audio_segments\", [])\n        if audio_segments:\n            # For simplicity, join all segment texts\n            text_snippet = \" \".join(seg[\"text\"] for seg in audio_segments).strip()\n        else:\n            text_snippet = \"No audio segments found.\"\n\n        # Build a clearer prompt\n        prompt = (\n            \"You are an expert in correlating video content with accompanying audio transcripts.\\n\"\n            \"Video: <|video|>\\n\"\n            f\"Audio Transcript: {text_snippet}\\n\"\n            \"Based on the visual content and the audio transcript above, provide a concise and insightful summary that connects both modalities. \"\n            \"Ensure your summary is complete and ends with a full stop.\\n\"\n            \"Summary:\"\n        )\n\n        # Summarize snippet\n        summary = getDescription([prompt], [video_path], generate_kwargs, nframes=48)\n        snippet_summaries.append(summary)\n        print(f\"[Snippet {i}] => {summary}\")\n\n    return snippet_summaries\n\n###########################\n# 5. Run Summaries\n###########################\nif __name__ == \"__main__\":\n    results = summarize_snippets(snippet_base=\"/kaggle/working/snippets\", snippet_count=10)\n    \n    # Build the output string\n    final_lines = [\"\"]\n    for i, summ in enumerate(results, start=1):\n        line = f\"Snippet {i:03d}: {summ}\"\n        print(line)                # Print to console\n        final_lines.append(line)   # Add to list\n    \n    # Combine all lines into a single string\n    final_output = \"\".join(final_lines)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:33:27.643803Z","iopub.execute_input":"2025-04-04T10:33:27.644159Z","iopub.status.idle":"2025-04-04T10:34:54.960607Z","shell.execute_reply.started":"2025-04-04T10:33:27.644128Z","shell.execute_reply":"2025-04-04T10:34:54.959768Z"}},"outputs":[{"name":"stdout","text":"[Snippet 1] => The image shows a man sitting at a desk in a busy office, talking on the phone. The audio transcript indicates that he is calling for Mr. Michael Anderson. This combination of visual and audio elements suggests that the man is trying to reach a specific person in the office and is using the telephone to communicate with them.\n[Snippet 2] => A man is sitting at a desk in a busy office, talking on the phone. He appears to be a manager or supervisor, as he is wearing a suit and tie. The office is filled with other people working, creating a lively atmosphere.\n[Snippet 3] => A man is sitting at a desk in a busy office, working on a computer. He is wearing a suit and tie, and appears to be focused on his work. The office is filled with other people, some of whom are sitting and working, while others are standing and talking. There are also a few chairs scattered around the\n[Snippet 4] => A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.\n[Snippet 5] => A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.\n[Snippet 6] => The image shows a man wearing glasses and a suit, sitting at a desk in a busy office. He is talking on the phone, likely discussing business matters. The audio transcript confirms that the man is saying \"yes\" to someone on his phone. This combination of visual and audio elements suggests that he is engaged in\n[Snippet 7] => A man is sitting at a desk in a busy office, talking on the phone. He is wearing glasses and appears to be engaged in an important conversation. The scene is set in the context of a workplace, with other people around him.\n[Snippet 8] => The image shows a man sitting in a train, talking on a cell phone. He is wearing a suit and appears to be a professional. The train is moving, and the man is focused on his conversation. This scene captures the modern lifestyle of people using their cell phones while commuting or traveling.\n[Snippet 9] => The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.\n[Snippet 10] => The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.\nSnippet 001: The image shows a man sitting at a desk in a busy office, talking on the phone. The audio transcript indicates that he is calling for Mr. Michael Anderson. This combination of visual and audio elements suggests that the man is trying to reach a specific person in the office and is using the telephone to communicate with them.\nSnippet 002: A man is sitting at a desk in a busy office, talking on the phone. He appears to be a manager or supervisor, as he is wearing a suit and tie. The office is filled with other people working, creating a lively atmosphere.\nSnippet 003: A man is sitting at a desk in a busy office, working on a computer. He is wearing a suit and tie, and appears to be focused on his work. The office is filled with other people, some of whom are sitting and working, while others are standing and talking. There are also a few chairs scattered around the\nSnippet 004: A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.\nSnippet 005: A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.\nSnippet 006: The image shows a man wearing glasses and a suit, sitting at a desk in a busy office. He is talking on the phone, likely discussing business matters. The audio transcript confirms that the man is saying \"yes\" to someone on his phone. This combination of visual and audio elements suggests that he is engaged in\nSnippet 007: A man is sitting at a desk in a busy office, talking on the phone. He is wearing glasses and appears to be engaged in an important conversation. The scene is set in the context of a workplace, with other people around him.\nSnippet 008: The image shows a man sitting in a train, talking on a cell phone. He is wearing a suit and appears to be a professional. The train is moving, and the man is focused on his conversation. This scene captures the modern lifestyle of people using their cell phones while commuting or traveling.\nSnippet 009: The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.\nSnippet 010: The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport gc\n\n# Free the model from memory\ndel model\n\n# Clear the GPU cache\ntorch.cuda.empty_cache()\n\n# Run garbage collection to free up unreferenced memory\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:39:25.439399Z","iopub.execute_input":"2025-04-04T10:39:25.439738Z","iopub.status.idle":"2025-04-04T10:39:25.461345Z","shell.execute_reply.started":"2025-04-04T10:39:25.439707Z","shell.execute_reply":"2025-04-04T10:39:25.460235Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b28a82cf6c89>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Free the model from memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Clear the GPU cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"if final_output.startswith(\"=== Final Summaries ===\"):\n    final_output = final_output[len(\"=== Final Summaries ===\"):].strip()\nfinal_output = final_output.replace(\"\\n\", \" \")\nprint(final_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:44:22.173225Z","iopub.execute_input":"2025-04-04T10:44:22.173531Z","iopub.status.idle":"2025-04-04T10:44:22.178329Z","shell.execute_reply.started":"2025-04-04T10:44:22.173509Z","shell.execute_reply":"2025-04-04T10:44:22.177401Z"}},"outputs":[{"name":"stdout","text":"Snippet 001: The image shows a man sitting at a desk in a busy office, talking on the phone. The audio transcript indicates that he is calling for Mr. Michael Anderson. This combination of visual and audio elements suggests that the man is trying to reach a specific person in the office and is using the telephone to communicate with them.Snippet 002: A man is sitting at a desk in a busy office, talking on the phone. He appears to be a manager or supervisor, as he is wearing a suit and tie. The office is filled with other people working, creating a lively atmosphere.Snippet 003: A man is sitting at a desk in a busy office, working on a computer. He is wearing a suit and tie, and appears to be focused on his work. The office is filled with other people, some of whom are sitting and working, while others are standing and talking. There are also a few chairs scattered around theSnippet 004: A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.Snippet 005: A man is talking on the phone while sitting at a desk in a busy office. He is discussing a lunch date with someone, and the conversation is about the time and location of the luch.Snippet 006: The image shows a man wearing glasses and a suit, sitting at a desk in a busy office. He is talking on the phone, likely discussing business matters. The audio transcript confirms that the man is saying \"yes\" to someone on his phone. This combination of visual and audio elements suggests that he is engaged inSnippet 007: A man is sitting at a desk in a busy office, talking on the phone. He is wearing glasses and appears to be engaged in an important conversation. The scene is set in the context of a workplace, with other people around him.Snippet 008: The image shows a man sitting in a train, talking on a cell phone. He is wearing a suit and appears to be a professional. The train is moving, and the man is focused on his conversation. This scene captures the modern lifestyle of people using their cell phones while commuting or traveling.Snippet 009: The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.Snippet 010: The video shows a busy airport terminal with a large digital display board displaying flight information. The audio transcript introduces a man named Ronald Friar, who is a passenger at the air terminal.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import requests\nngrok_url = \"https://17e3-2409-40e1-1067-f605-6840-f09a-93ec-e92f.ngrok-free.app/upload\"\nresponse = requests.post(ngrok_url, data={\"output\": final_output})\n\nif response.status_code == 200:\n    print(\"Output sent successfully!\")\nelse:\n    print(\"Failed to send output:\", response.text)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:43:33.398937Z","iopub.execute_input":"2025-04-04T10:43:33.399313Z","iopub.status.idle":"2025-04-04T10:43:34.025898Z","shell.execute_reply.started":"2025-04-04T10:43:33.399285Z","shell.execute_reply":"2025-04-04T10:43:34.025185Z"}},"outputs":[{"name":"stdout","text":"Failed to send output: \n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}